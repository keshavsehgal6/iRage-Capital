{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "from scipy import signal\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Import RandomForest Classifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn import metrics\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stock = pd.read_csv('/Users/k0s00ks/Documents/iRage Capital/Data Science Assignment (Latest)/s1.csv')\n",
    "\n",
    "# Convert the Date column to Date and time seperately\n",
    "stock['date'] = pd.to_datetime(stock['date'])\n",
    "stock['Time'],stock['Date']= stock['date'].apply(lambda x:x.time()), stock['date'].apply(lambda x:x.date())\n",
    "stock['Hour'] = stock['date'].apply(lambda x:x.hour)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cols = stock.columns\n",
    "cols.drop('30secAhead', '1minAhead')\n",
    "stock['Date'] = pd.to_datetime(stock['Date'])\n",
    "y_cols = ['30secAhead', '1minAhead', 'Date', 'Time', 'date']\n",
    "X, y = stock[cols], stock[y_cols]\n",
    "X_train, X_test = X.loc[X['Date'] < pd.to_datetime('2016-10-15', format = '%Y-%m-%d' )], X.loc[X['Date'] >= pd.to_datetime('2016-10-15', format = '%Y-%m-%d' )]\n",
    "y_train, y_test = y.loc[y['Date'] < pd.to_datetime('2016-10-15', format = '%Y-%m-%d' )], y.loc[y['Date'] >= pd.to_datetime('2016-10-15', format = '%Y-%m-%d' )]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Type 1: Random Forest Regression\n",
    "Now we start to build models to predict the 30 second change. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done   1 out of   8 | elapsed: 10.5min remaining: 73.2min\n",
      "[Parallel(n_jobs=8)]: Done   8 out of   8 | elapsed: 10.8min finished\n",
      "/Users/k0s00ks/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:25: FutureWarning: sort(columns=....) is deprecated, use sort_values(by=.....)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([u'bidx0', u'sidx0', u'bidx3', u'f25', u'f129', u'bidx1', u'bsz0',\n",
      "       u'f85', u'f145', u'f146', u'f56', u'f128', u'f148', u'f114', u'f113',\n",
      "       u'f112', u'f55', u'f130', u'bidx4', u'f121'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done   1 out of   8 | elapsed:    2.0s remaining:   14.1s\n",
      "[Parallel(n_jobs=8)]: Done   8 out of   8 | elapsed:    6.4s finished\n",
      "[Parallel(n_jobs=8)]: Done   1 out of   8 | elapsed:    0.6s remaining:    3.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy is : -0.647607499446 and train accuracy is : 0.937304438359\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done   8 out of   8 | elapsed:    2.3s finished\n"
     ]
    }
   ],
   "source": [
    "model_cols_X = ['b0', 'a0', 'bsz0', 'bidx0', 'sidx0', 'ssz0', 'bsz1', 'bidx1', \n",
    "                'sidx1', 'ssz1', 'bsz2', 'bidx2', 'sidx2', 'ssz2', 'bsz3', 'bidx3', \n",
    "                'sidx3', 'ssz3', 'bsz4', 'bidx4', 'sidx4', 'ssz4', 'f25', 'f26', \n",
    "                'f27', 'f28', 'f29', 'f30', 'f31', 'f32', 'f33', 'f34', 'f35', 'f36', \n",
    "                'f37', 'f38', 'f39', 'f40', 'f41', 'f42', 'f43', 'f44', 'f45', 'f46', \n",
    "                'f47', 'f48', 'f49', 'f50', 'f51', 'f52', 'f53', 'f54', 'f55', 'f56', \n",
    "                'f57', 'f58', 'b0_cm', 'a0_cm', 'bsz0_cm', 'bidx0_cm', 'sidx0_cm', 'ssz0_cm',\n",
    "                'bsz1_cm', 'bidx1_cm', 'sidx1_cm', 'ssz1_cm', 'bsz2_cm', 'bidx2_cm', 'sidx2_cm',\n",
    "                'ssz2_cm', 'bsz3_cm', 'bidx3_cm', 'sidx3_cm', 'ssz3_cm', 'bsz4_cm', 'bidx4_cm', \n",
    "                'sidx4_cm', 'ssz4_cm', 'f82', 'f83', 'f84', 'f85', 'f86', 'f87', 'f88', 'f89', \n",
    "                'f90', 'f91', 'f92', 'f93', 'f94', 'f95', 'f96', 'f97', 'f98', 'f99', 'f100', \n",
    "                'f101', 'f102', 'f103', 'f104', 'f105', 'f106', 'f107', 'f108', 'f109', 'f110', \n",
    "                'f111', 'f112', 'f113', 'f114', 'f115', 'f116', 'f117', 'f118', 'f119', 'f120', \n",
    "                'f121', 'f122', 'f123', 'f124', 'f125', 'f126', 'f127', 'f128', 'f129', 'f130', \n",
    "                'f131', 'f132', 'f133', 'f134', 'f139', 'f140', 'f141', 'f142', 'f143', 'f144', \n",
    "                'f145', 'f146', 'f147', 'f148','Hour']\n",
    "\n",
    "model_cols_y = ['30secAhead', '1minAhead']\n",
    "\n",
    "rfr0 = RandomForestRegressor(n_jobs=-1, verbose=1)\n",
    "rfr0.fit(X_train[model_cols_X], y_train['30secAhead'])\n",
    "\n",
    "imporatnce_matrix_0 = pd.DataFrame(0, index = X_train[model_cols_X].columns, columns = ['Importance'])\n",
    "imporatnce_matrix_0['Importance'] = rfr0.feature_importances_\n",
    "print (imporatnce_matrix_0.sort('Importance', ascending=False).head(20).index)\n",
    "\n",
    "train_accuracy_rfr0 = rfr0.score(X_train[model_cols_X], y_train['30secAhead'])\n",
    "test_accuracy_rfr0 = rfr0.score(X_test[model_cols_X], y_test['30secAhead'])\n",
    "\n",
    "print ('Test accuracy is : ' + str(test_accuracy_rfr0) + ' and train accuracy is : ' + str(train_accuracy_rfr0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that though score on train data is coming out to be awesome, the result on data fails horribly. The RandomForest model is currently overfitting. We may try the model with less variables.\n",
    "Using the importance matrix we select the top 20 most important variables for building the ensemble of trees.\n",
    "\n",
    "# MODEL 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/k0s00ks/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:2: FutureWarning: sort(columns=....) is deprecated, use sort_values(by=.....)\n",
      "  from ipykernel import kernelapp as app\n",
      "[Parallel(n_jobs=8)]: Done   1 out of   8 | elapsed:  1.4min remaining:  9.8min\n",
      "[Parallel(n_jobs=8)]: Done   8 out of   8 | elapsed:  1.4min finished\n",
      "/Users/k0s00ks/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:4: FutureWarning: sort(columns=....) is deprecated, use sort_values(by=.....)\n",
      "[Parallel(n_jobs=8)]: Done   1 out of   8 | elapsed:    0.6s remaining:    4.4s\n",
      "[Parallel(n_jobs=8)]: Done   8 out of   8 | elapsed:    1.4s finished\n",
      "/Users/k0s00ks/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:5: FutureWarning: sort(columns=....) is deprecated, use sort_values(by=.....)\n",
      "[Parallel(n_jobs=8)]: Done   1 out of   8 | elapsed:    0.3s remaining:    2.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy is : -0.475969322569 and train accuracy is : 0.944697982064\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done   8 out of   8 | elapsed:    0.8s finished\n"
     ]
    }
   ],
   "source": [
    "rfr1 = RandomForestRegressor(n_jobs=-1, verbose=1)\n",
    "rfr1.fit(X_train[imporatnce_matrix_0.sort('Importance', ascending=False).head(20).index], y_train['30secAhead'])\n",
    "\n",
    "train_accuracy_rfr1 = rfr1.score(X_train[imporatnce_matrix_0.sort('Importance', ascending=False).head(20).index], y_train['30secAhead'])\n",
    "test_accuracy_rfr1 = rfr1.score(X_test[imporatnce_matrix_0.sort('Importance', ascending=False).head(20).index], y_test['30secAhead'])\n",
    "\n",
    "print ('Test accuracy is : ' + str(test_accuracy_rfr1) + ' and train accuracy is : ' + str(train_accuracy_rfr1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here also we see that the model is performing horribly in predicting the 30secAhead changes. A value of less than shows the model is performing worse than random predictions.\n",
    "\n",
    "Now we would try to predict just the movement of prices and not its value. The classifier consists of 3 classes:\n",
    "\n",
    "MOVE UP(+ve), NO MOVE(0), MOVE DOWN(-ve)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Type 2 : Random Forest Classifier\n",
    "For this model we create the predictor variable showing the movement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done   1 out of   8 | elapsed:   26.3s remaining:  3.1min\n",
      "[Parallel(n_jobs=8)]: Done   8 out of   8 | elapsed:   26.3s finished\n",
      "[Parallel(n_jobs=8)]: Done   1 out of   8 | elapsed:    0.7s remaining:    4.9s\n",
      "[Parallel(n_jobs=8)]: Done   8 out of   8 | elapsed:    2.2s finished\n",
      "[Parallel(n_jobs=8)]: Done   1 out of   8 | elapsed:    1.9s remaining:   13.4s\n",
      "[Parallel(n_jobs=8)]: Done   8 out of   8 | elapsed:    6.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.396001061155 0.995051299088\n"
     ]
    }
   ],
   "source": [
    "# New binary predictor variables\n",
    "def create_buckets(data):\n",
    "    buckets = np.zeros(data.shape[0])\n",
    "    buckets[data > 0] = 1\n",
    "    buckets[data == 0] = 0\n",
    "    buckets[data < 0] = -1\n",
    "    \n",
    "    return (buckets)\n",
    "\n",
    "#30secAhead\n",
    "\n",
    "y_train_binary = create_buckets (y_train['30secAhead'])\n",
    "y_test_binary = create_buckets (y_test['30secAhead']) \n",
    "\n",
    "rfc0 = RandomForestClassifier(n_jobs=-1, verbose=1)\n",
    "rfc0.fit(X_train[model_cols_X], y_train_binary)\n",
    "\n",
    "imporatnce_matrix_rfc0 = pd.DataFrame(0, index = X_train[model_cols_X].columns, columns = ['Importance'])\n",
    "imporatnce_matrix_rfc0['Importance'] = rfc0.feature_importances_\n",
    "\n",
    "test_accuracy = rfc0.score(X_test[model_cols_X], y_test_binary)\n",
    "train_accuracy = rfc0.score(X_train[model_cols_X], y_train_binary)\n",
    "print (test_accuracy, train_accuracy) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For further model comparisions we are making a function which can handle the models and produce the results.\n",
    "\n",
    "accu_above_level: Its a special function which will seperate the predictions setting very high threshold giving us better accuracies on trades we can go in. \n",
    "\n",
    "Accu_above_level is a representative of ROC Metric used for 2 class classification. ROC is not being used as the problem is of Multi Class Classification\n",
    "\n",
    "# Assumption\n",
    "In addition to that accuracy on Up Move and Down Move is being considered as these are trade producing signals.\n",
    "\n",
    "Here positive and negative trades refer to Long Side and Short Side trades. Transaction cost is not being considered which will go in when trading stretegies are formed.\n",
    "\n",
    "# Caution\n",
    "Though the modeling is being done on just a single set of test and train data but thorough backtessting needs to be done further with monger time period of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def RF_model(model, feature_list, verbose = True):\n",
    "    \n",
    "    model.fit(X_train[feature_list], y_train_binary)\n",
    "\n",
    "    test_accuracy = model.score(X_test[feature_list], y_test_binary)\n",
    "    train_accuracy = model.score(X_train[feature_list], y_train_binary)\n",
    "    \n",
    "    if(verbose == True):\n",
    "        print ('Model is ' + str(model))\n",
    "        print ('Test accuracy is : ' + str(test_accuracy) + ' and train accuracy is : ' + str(train_accuracy))\n",
    "    \n",
    "    imporatnce_matrix = pd.DataFrame(0, index = feature_list, columns = ['Importance'])\n",
    "    imporatnce_matrix['Importance'] = model.feature_importances_ \n",
    "    \n",
    "    return (test_accuracy, train_accuracy)#, imporatnce_matrix)\n",
    "\n",
    "# We would like to check the accuracy of predictions at various levels of probability\n",
    "def pred_matrix(y_test, model):\n",
    "    prediction = model.predict_proba(X_test[feature_list])\n",
    "    prediction_matrix = pd.DataFrame(0, index = y_test.index, columns = ['date', 'Date','30secAhead', 'Original_direction','+ve_dir_proba','-ve_dir_proba'])\n",
    "    prediction_matrix['date'] = y_test['date']\n",
    "    prediction_matrix['Date'] = y_test['Date']\n",
    "    prediction_matrix['30secAhead'] = y_test_binary\n",
    "    prediction_matrix['Original_direction'] = y_test_binary\n",
    "    prediction_matrix['-ve_dir_proba'] = prediction[:,0]\n",
    "    prediction_matrix['0_dir_proba'] = prediction[:,1]\n",
    "    prediction_matrix['+ve_dir_proba'] = prediction[:,2]\n",
    "\n",
    "    return (prediction_matrix)\n",
    "\n",
    "def accu_above_level(df ,po_lvl , ne_lvl):\n",
    "    total = df.shape[0]\n",
    "    prediction = np.zeros(total)\n",
    "    prediction[df['+ve_dir_proba'].values > po_lvl] = 1\n",
    "    prediction[df['-ve_dir_proba'].values > ne_lvl] = -1\n",
    "    number_of_predictions = np.sum(prediction * prediction)\n",
    "    cnf_matrix = confusion_matrix(prediction_matrix['Original_direction'], prediction)\n",
    "    pos_prior, neg_prior = np.sum(cnf_matrix[2,:])/ np.sum(cnf_matrix) , np.sum(cnf_matrix[0,:])/ np.sum(cnf_matrix)\n",
    "    pos_post, neg_post = cnf_matrix[2,2]/ np.sum(cnf_matrix[:,2]) , cnf_matrix[0,0]/ np.sum(cnf_matrix[:,0])\n",
    "    print ('Posteriors for +ve, -ve are : %2f and %2f; where as priors were %2f and %2f with %d trades available in test period.' %(pos_post, neg_post, pos_prior, neg_prior, number_of_predictions))\n",
    "    print ('Number of buy trades: %d and short trades: %d' %(np.count_nonzero(prediction == 1), np.count_nonzero(prediction == -1)))\n",
    "    return (cnf_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RF MODEL Iteration 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([u'f148', u'f147', u'f146', u'f145', u'f117', u'f116', u'f122', u'f119'], dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/k0s00ks/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:4: FutureWarning: sort(columns=....) is deprecated, use sort_values(by=.....)\n",
      "[Parallel(n_jobs=8)]: Done   1 out of   8 | elapsed:    5.6s remaining:   39.5s\n",
      "[Parallel(n_jobs=8)]: Done   8 out of   8 | elapsed:    5.8s finished\n",
      "[Parallel(n_jobs=8)]: Done   1 out of   8 | elapsed:    0.1s remaining:    1.0s\n",
      "[Parallel(n_jobs=8)]: Done   8 out of   8 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=8)]: Done   1 out of   8 | elapsed:    0.3s remaining:    2.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model is RandomForestClassifier(bootstrap=True, compute_importances=None,\n",
      "            criterion=gini, max_depth=None, max_features=auto,\n",
      "            min_density=None, min_samples_leaf=1, min_samples_split=2,\n",
      "            n_estimators=10, n_jobs=-1, oob_score=False, random_state=None,\n",
      "            verbose=1)\n",
      "Test accuracy is : 0.400314886157 and train accuracy is : 0.995584136544\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done   8 out of   8 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=8)]: Done   1 out of   8 | elapsed:    0.2s remaining:    1.1s\n",
      "[Parallel(n_jobs=8)]: Done   8 out of   8 | elapsed:    0.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Posteriors for +ve, -ve are : 0.430657 and 0.440596; where as priors were 0.410869 and 0.385857 with 7956 trades available in test period.\n",
      "Number of positive trades: 5069 and negative trades: 2887\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 1272, 63560,  2074],\n",
       "       [  414, 34021,   812],\n",
       "       [ 1201, 67859,  2183]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_of_features = 8\n",
    "rfc2 = RandomForestClassifier(n_jobs=-1, verbose=1)\n",
    "feature_list =imporatnce_matrix_rfc0.sort('Importance', ascending=False).head(no_of_features).index \n",
    "print (feature_list)\n",
    "RF_model(rfc2, feature_list)\n",
    "# Prepare the prediction matrix\n",
    "prediction_matrix = pred_matrix(y_test, rfc2,imporatnce_matrix_rfc0)\n",
    "# Check the accuracy above a particular level\n",
    "accu_above_level(prediction_matrix,0.7, 0.7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RF MODEL Iteration 3:\n",
    "\n",
    "For the model iteration 3 we will select the variables which were highly correlated in the correlation matrix analysed. In addition to this we will take into consideration the variables having high importance in Model 1 of RF Classifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'bidx0', u'sidx0', u'bidx2', u'sidx2', u'bidx4', u'sidx4', u'f26', u'f27', u'bidx1', u'bidx3', u'bsz2_cm', u'bsz3_cm', u'bsz4_cm', u'f82', u'f114']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done   1 out of   8 | elapsed:    7.4s remaining:   51.7s\n",
      "[Parallel(n_jobs=8)]: Done   8 out of   8 | elapsed:    7.4s finished\n",
      "[Parallel(n_jobs=8)]: Done   1 out of   8 | elapsed:    0.3s remaining:    2.2s\n",
      "[Parallel(n_jobs=8)]: Done   8 out of   8 | elapsed:    0.8s finished\n",
      "[Parallel(n_jobs=8)]: Done   1 out of   8 | elapsed:    0.6s remaining:    4.4s\n",
      "[Parallel(n_jobs=8)]: Done   8 out of   8 | elapsed:    1.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model is RandomForestClassifier(bootstrap=True, compute_importances=None,\n",
      "            criterion=gini, max_depth=None, max_features=auto,\n",
      "            min_density=None, min_samples_leaf=1, min_samples_split=2,\n",
      "            n_estimators=10, n_jobs=-1, oob_score=False, random_state=None,\n",
      "            verbose=1)\n",
      "Test accuracy is : 0.404836328404 and train accuracy is : 0.970128743884\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done   1 out of   8 | elapsed:    0.3s remaining:    2.2s\n",
      "[Parallel(n_jobs=8)]: Done   8 out of   8 | elapsed:    0.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Posteriors for +ve, -ve are : 0.483295 and 0.467973; where as priors were 0.410869 and 0.385857 with 12029 trades available in test period.\n",
      "Number of positive trades: 5597 and negative trades: 6432\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 3010, 62041,  1855],\n",
       "       [ 1187, 33023,  1037],\n",
       "       [ 2235, 66303,  2705]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_of_features = 8\n",
    "rfc3 = RandomForestClassifier(n_jobs=-1, verbose=1)\n",
    "# rfc2 = 0\n",
    "feature_list =[u'bidx0', u'sidx0', u'bidx2', u'sidx2', u'bidx4', u'sidx4', u'f26',\n",
    "       u'f27', u'bidx1', u'bidx3', u'bsz2_cm', u'bsz3_cm', u'bsz4_cm', u'f82',\n",
    "       u'f114']\n",
    "print (feature_list)\n",
    "RF_model(rfc3, feature_list)\n",
    "# Prepare the prediction matrix\n",
    "prediction_matrix = pred_matrix(y_test, rfc3,imporatnce_matrix_rfc0)\n",
    "# Check the accuracy above a particular level\n",
    "accu_above_level(prediction_matrix,0.7, 0.7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observe that with this rejig we are able to achieve higher number of trades as well as high accuracy on these trades selected. \n",
    "\n",
    "# RF MODEL Iteration 4:\n",
    "\n",
    "For the 4th iteration we will tweak the parameters of the basic model to achieve better results. The model shown here is obtained after a lot of tweaking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'bidx0', u'sidx0', u'bidx2', u'sidx2', u'bidx4', u'sidx4', u'f26', u'f27', u'bidx1', u'bidx3', u'bsz2_cm', u'bsz3_cm', u'bsz4_cm', u'f82', u'f114', u'f148', u'f147', u'f146', u'f145', u'f117', u'f116', u'f122', u'f119']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done   1 out of   8 | elapsed:   25.7s remaining:  3.0min\n",
      "[Parallel(n_jobs=8)]: Done   8 out of   8 | elapsed:   26.6s finished\n",
      "[Parallel(n_jobs=8)]: Done   1 out of   8 | elapsed:    0.3s remaining:    2.2s\n",
      "[Parallel(n_jobs=8)]: Done   8 out of   8 | elapsed:    0.9s finished\n",
      "[Parallel(n_jobs=8)]: Done   1 out of   8 | elapsed:    0.7s remaining:    5.0s\n",
      "[Parallel(n_jobs=8)]: Done   8 out of   8 | elapsed:    1.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model is RandomForestClassifier(bootstrap=True, compute_importances=None,\n",
      "            criterion=entropy, max_depth=None, max_features=5,\n",
      "            min_density=None, min_samples_leaf=1, min_samples_split=2,\n",
      "            n_estimators=20, n_jobs=-1, oob_score=False,\n",
      "            random_state=12345, verbose=1)\n",
      "Test accuracy is : 0.415615123763 and train accuracy is : 0.998619368534\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done   1 out of   8 | elapsed:    0.3s remaining:    2.3s\n",
      "[Parallel(n_jobs=8)]: Done   8 out of   8 | elapsed:    1.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Posteriors for +ve, -ve are : 0.602390 and 0.532913; where as priors were 0.410869 and 0.385857 with 2364 trades available in test period.\n",
      "Number of positive trades: 1255 and negative trades: 1109\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[  591, 65967,   348],\n",
       "       [  208, 34888,   151],\n",
       "       [  310, 70177,   756]])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_of_features = 8\n",
    "rfc4 = RandomForestClassifier(compute_importances=None, criterion = 'entropy',\n",
    "                              min_density=None, min_samples_leaf=1, min_samples_split=2,\n",
    "                              n_estimators=20, oob_score=False, random_state=12345\n",
    "                              ,n_jobs=-1, verbose=1,max_features = 5)\n",
    "# rfc2 = 0\n",
    "feature_list =[u'bidx0', u'sidx0', u'bidx2', u'sidx2', u'bidx4', u'sidx4', u'f26',\n",
    "       u'f27', u'bidx1', u'bidx3', u'bsz2_cm', u'bsz3_cm', u'bsz4_cm', u'f82',\n",
    "       u'f114',u'f148', u'f147', u'f146', u'f145', u'f117', u'f116', u'f122', u'f119']\n",
    "print (feature_list)\n",
    "RF_model(rfc4, feature_list)\n",
    "# Prepare the prediction matrix\n",
    "prediction_matrix = pred_matrix(y_test, rfc4,imporatnce_matrix_rfc0)\n",
    "# Check the accuracy above a particular level\n",
    "accu_above_level(prediction_matrix,0.7, 0.7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observe that the model is giving us good accuracy trades but all the models are still overfitting which is a rare phenomenon in Random Forest. \n",
    "\n",
    "The number of buy and sell trades\n",
    "\n",
    "We will move to a more complicated tree algorithm: XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Type 3: XGBoost Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def XGB_model(model, feature_list, verbose = True):\n",
    "    \n",
    "    model.fit(X_train[feature_list], y_train_binary)\n",
    "\n",
    "    test_accuracy = model.score(X_test[feature_list], y_test_binary)\n",
    "    train_accuracy = model.score(X_train[feature_list], y_train_binary)\n",
    "    \n",
    "    if(verbose == True):\n",
    "        print ('Model is ' + str(model))\n",
    "        print ('Test accuracy is : ' + str(test_accuracy) + ' and train accuracy is : ' + str(train_accuracy))\n",
    "    \n",
    "    return (test_accuracy, train_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGB Model 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model is XGBClassifier(base_score=0.5, colsample_bytree=0.8, gamma=0,\n",
      "       learning_rate=0.1, max_delta_step=0, max_depth=5,\n",
      "       min_child_weight=1, n_estimators=200, nthread=-1,\n",
      "       objective=multi:softprob, seed=27, silent=True, subsample=0.8)\n",
      "Test accuracy is : 0.420909363538 and train accuracy is : 0.527841296413\n",
      "Posteriors for +ve, -ve are : 0.555975 and 0.421912; where as priors were 0.410869 and 0.385857 with 58069 trades available in test period.\n",
      "Number of buy trades: 3707 and short trades: 54362\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[22936, 42706,  1264],\n",
       "       [10396, 24469,   382],\n",
       "       [21030, 48152,  2061]])"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb1 = xgb.XGBClassifier(n_estimators=20,\n",
    " learning_rate =0.1,\n",
    " max_depth=5,\n",
    " min_child_weight=1,\n",
    " gamma=0,\n",
    " subsample=0.8,\n",
    " colsample_bytree=0.8,\n",
    " objective= 'multi:softmax',\n",
    " seed=27,\n",
    " nthread=-1)\n",
    "\n",
    "feature_list =[u'bidx0', u'sidx0', u'bidx2', u'sidx2', u'bidx4', u'sidx4', u'f26',\n",
    "       u'f27', u'bidx1', u'bidx3', u'bsz2_cm', u'bsz3_cm', u'bsz4_cm', u'f82',\n",
    "       u'f114',u'f148', u'f147', u'f146', u'f145', u'f117', u'f116', u'f122', u'f119']\n",
    "\n",
    "\n",
    "XGB_model(xgb1, feature_list)\n",
    "# Prepare the prediction matrix\n",
    "prediction_matrix = pred_matrix(y_test, xgb1,imporatnce_matrix_rfc0)\n",
    "# Check the accuracy above a particular level\n",
    "accu_above_level(prediction_matrix,0.7, 0.7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observe that the trades produced are very high with a decent number of accuracy. In addition to this the model is not overfitting; which is a good thing as compared to our previous models.\n",
    "\n",
    "# XGB MODEL 2: \n",
    "We shift to a simpler model with more number of trees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model is XGBClassifier(base_score=0.5, colsample_bytree=1, gamma=0, learning_rate=0.05,\n",
      "       max_delta_step=0, max_depth=3, min_child_weight=1, n_estimators=200,\n",
      "       nthread=-1, objective=multi:softprob, seed=0, silent=True,\n",
      "       subsample=1)\n",
      "Test accuracy is : 0.432933862373 and train accuracy is : 0.457088248238\n",
      "Posteriors for +ve, -ve are : 0.621339 and 0.425828; where as priors were 0.410869 and 0.385857 with 48481 trades available in test period.\n",
      "Number of buy trades: 478 and short trades: 48003\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[20441, 46329,   136],\n",
       "       [ 8527, 26675,    45],\n",
       "       [19035, 51911,   297]])"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb2 = xgb.XGBClassifier(n_estimators=200,\n",
    " learning_rate =0.01,\n",
    " objective= 'multi:softmax')\n",
    "\n",
    "feature_list =[u'bidx0', u'sidx0', u'bidx2', u'sidx2', u'bidx4', u'sidx4', u'f26',\n",
    "       u'f27', u'bidx1', u'bidx3', u'bsz2_cm', u'bsz3_cm', u'bsz4_cm', u'f82',\n",
    "       u'f114',u'f148', u'f147', u'f146', u'f145', u'f117', u'f116', u'f122', u'f119']\n",
    "\n",
    "\n",
    "XGB_model(xgb2, feature_list)\n",
    "# Prepare the prediction matrix\n",
    "prediction_matrix = pred_matrix(y_test, xgb2)\n",
    "# Check the accuracy above a particular level\n",
    "accu_above_level(prediction_matrix,0.7, 0.7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this model the test accuracy has increased a little but at the same time we notice that most of the trades produced are negative trades. This skew in the predictions need to be handled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model is XGBClassifier(base_score=0.5, colsample_bytree=1, gamma=1, learning_rate=0.01,\n",
      "       max_delta_step=0, max_depth=3, min_child_weight=1, n_estimators=200,\n",
      "       nthread=-1, objective=multi:softprob, seed=27, silent=True,\n",
      "       subsample=1)\n",
      "Test accuracy is : 0.439300791252 and train accuracy is : 0.446893147753\n",
      "Posteriors for +ve, -ve are : 0.589481 and 0.590368; where as priors were 0.410869 and 0.385857 with 7091 trades available in test period.\n",
      "Number of buy trades: 1464 and short trades: 5627\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 3322, 63208,   376],\n",
       "       [  695, 34327,   225],\n",
       "       [ 1610, 68770,   863]])"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb3 = xgb.XGBClassifier(n_estimators=200,\n",
    " learning_rate =0.01,\n",
    " gamma =1,\n",
    " objective= 'multi:softmax',\n",
    " seed=27,\n",
    " nthread=-1)\n",
    "\n",
    "feature_list =[u'bidx0', u'sidx0', u'bidx2', u'sidx2', u'bidx4', u'sidx4', u'f26',\n",
    "       u'f27', u'bidx1', u'bidx3', u'bsz2_cm', u'bsz3_cm', u'bsz4_cm', u'f82',\n",
    "       u'f114',u'f148', u'f147', u'f146', u'f145', u'f117', u'f116', u'f122', u'f119']\n",
    "\n",
    "\n",
    "XGB_model(xgb3, feature_list)\n",
    "# Prepare the prediction matrix\n",
    "prediction_matrix = pred_matrix(y_test, xgb3)\n",
    "# Check the accuracy above a particular level\n",
    "accu_above_level(prediction_matrix,0.5, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Posteriors for +ve, -ve are : 0.579422 and 0.494019; where as priors were 0.410869 and 0.385857 with 41212 trades available in test period.\n",
      "Number of buy trades: 6434 and short trades: 34778\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[17181, 47938,  1787],\n",
       "       [ 6204, 28124,   919],\n",
       "       [11393, 56122,  3728]])"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accu_above_level(prediction_matrix,0.45, 0.44)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this level with similar number of trades accuracy of short trades has increased. In addition to this we are getting good number of buy trades too. "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
